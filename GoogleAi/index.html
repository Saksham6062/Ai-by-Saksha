<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google AI Model Playground (Light Theme)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        /* Custom scrollbar for light theme */
        ::-webkit-scrollbar {
            width: 8px;
        }
        ::-webkit-scrollbar-track {
            background: #f3f4f6; /* gray-100 */
        }
        ::-webkit-scrollbar-thumb {
            background: #d1d5db; /* gray-300 */
            border-radius: 4px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #9ca3af; /* gray-400 */
        }
        .model-interface {
            animation: fadeIn 0.5s ease-in-out;
        }
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .chat-bubble {
            max-width: 80%;
            word-wrap: break-word;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800">

    <div class="flex h-screen">
        <!-- Sidebar Navigation -->
        <aside id="sidebar" class="w-72 bg-white border-r border-gray-200 p-4 flex flex-col overflow-y-auto">
            <header class="mb-6">
                <h1 class="text-xl font-bold text-gray-900">Google AI Models</h1>
                <p class="text-sm text-gray-500">Select a model family to explore.</p>
            </header>
            <nav id="model-navigation" class="flex-grow">
                <!-- Navigation links will be dynamically inserted here -->
            </nav>
            <footer class="text-xs text-gray-400 mt-4">
                <p>Conceptual Interface. Live models use Gemini and Imagen APIs.</p>
            </footer>
        </aside>

        <!-- Main Content Area -->
        <main class="flex-1 p-4 sm:p-6 md:p-8 overflow-y-auto">
            <div id="content-container">
                <!-- Welcome Screen -->
                <div id="welcome-screen" class="flex flex-col items-center justify-center h-full text-center">
                    <svg class="w-24 h-24 text-blue-500 mb-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path></svg>
                    <h2 class="text-3xl font-bold text-gray-900 mb-2">AI Model Playground</h2>
                    <p class="text-gray-500 max-w-md">Select a model from the sidebar to begin exploring its capabilities. This interface provides a hands-on feel for Google's diverse and powerful AI ecosystem.</p>
                </div>

                <!-- Model Interfaces Container -->
                <div id="model-interfaces" class="hidden">
                    <!-- Text Generation Interface (for Gemini & Gemma) -->
                    <div id="text-generation-interface" class="model-interface hidden h-full flex flex-col">
                        <header class="mb-4">
                            <h3 class="text-2xl font-bold" id="text-model-title"></h3>
                            <p class="text-gray-500" id="text-model-description"></p>
                        </header>
                        <div class="mb-4 flex items-center space-x-4">
                            <label for="text-model-selector" class="text-sm font-medium">Select Model:</label>
                            <select id="text-model-selector" class="bg-white border border-gray-300 rounded-md px-3 py-2 text-sm focus:outline-none focus:ring-2 focus:ring-blue-500"></select>
                        </div>
                        <div id="chat-container" class="flex-grow bg-gray-100 rounded-lg p-4 overflow-y-auto mb-4 border border-gray-200">
                            <!-- Chat messages will be appended here -->
                        </div>
                        <div class="flex items-center bg-white rounded-lg px-2 border border-gray-300 focus-within:ring-2 focus-within:ring-blue-500">
                            <input id="text-prompt-input" type="text" class="w-full bg-transparent p-4 focus:outline-none" placeholder="Enter your prompt here...">
                            <button id="send-text-prompt-btn" class="bg-blue-600 hover:bg-blue-700 text-white rounded-lg p-3 transition-colors disabled:bg-gray-400 disabled:cursor-not-allowed">
                                <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                            </button>
                        </div>
                    </div>

                    <!-- Image Generation Interface -->
                    <div id="image-generation-interface" class="model-interface hidden h-full flex flex-col">
                         <header class="mb-4">
                            <h3 class="text-2xl font-bold" id="image-model-title"></h3>
                            <p class="text-gray-500" id="image-model-description"></p>
                        </header>
                         <div class="mb-4 flex items-center space-x-4">
                            <label for="image-model-selector" class="text-sm font-medium">Select Model:</label>
                            <select id="image-model-selector" class="bg-white border border-gray-300 rounded-md px-3 py-2 text-sm focus:outline-none focus:ring-2 focus:ring-blue-500"></select>
                        </div>
                        <div class="flex items-center bg-white rounded-lg px-2 mb-4 border border-gray-300 focus-within:ring-2 focus-within:ring-blue-500">
                            <input id="image-prompt-input" type="text" class="w-full bg-transparent p-4 focus:outline-none" placeholder="Describe the image you want to create...">
                            <button id="send-image-prompt-btn" class="bg-blue-600 hover:bg-blue-700 text-white rounded-lg p-3 transition-colors disabled:bg-gray-400 disabled:cursor-not-allowed">
                                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12v7a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h7"/><line x1="16" x2="22" y1="5" y2="5"/><line x1="19" x2="19" y1="2" y2="8"/><circle cx="9" cy="9" r="2"/><path d="m21 15-3.086-3.086a2 2 0 0 0-2.828 0L6 21"/></svg>
                            </button>
                        </div>
                         <div id="image-display-area" class="flex-grow bg-gray-100 rounded-lg p-4 flex items-center justify-center border border-gray-200">
                            <div id="image-placeholder" class="text-gray-500">Your generated image will appear here.</div>
                         </div>
                    </div>
                </div>
            </div>
        </main>
    </div>

<script type="module">
    // --- MODEL DATA ---
    const modelData = {
        "Gemini": {
            type: 'text',
            title: 'Gemini Family',
            description: 'A family of multimodal models capable of understanding and reasoning across text, images, video, and audio.',
            models: [
                { id: 'gemini-ultra', name: 'Gemini Ultra', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'gemini-pro', name: 'Gemini Pro', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'gemini-flash', name: 'Gemini Flash', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'gemini-nano', name: 'Gemini Nano', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'gemini-2.5-pro', name: 'Gemini 2.5 Pro', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'gemini-2.5-flash', name: 'Gemini 2.5 Flash', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'gemini-2.5-flash-lite', name: 'Gemini 2.5 Flash-Lite', api: 'gemini-2.5-flash-preview-05-20' }
            ]
        },
        "Gemma": {
            type: 'text',
            title: 'Gemma Family',
            description: 'A family of lightweight, state-of-the-art open models built from the same research and technology used to create Gemini models.',
            models: [
                { id: 'gemma-open', name: 'Gemma (Open-weight)', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'gemma-3n', name: 'Gemma 3n (e.g., E4B, E2B)', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'gemma-3', name: 'Gemma 3 (e.g., 27B, 12B, 4B, 1B)', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'gemma-2', name: 'Gemma 2 (e.g., 27B, 9B, 2B)', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'codegemma', name: 'CodeGemma (e.g., 7B, 2B)', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'paligemma', name: 'PaliGemma', api: 'mock' },
                { id: 'medgemma', name: 'MedGemma', api: 'mock' },
                { id: 'shieldgemma', name: 'ShieldGemma', api: 'mock' },
                { id: 'embeddinggemma', name: 'EmbeddingGemma', api: 'mock' },
                { id: 't5gemma', name: 'T5Gemma', api: 'mock' }
            ]
        },
        "Imagen": {
            type: 'image',
            title: 'Imagen Family',
            description: 'Advanced text-to-image models for generating, editing, and understanding images with a high degree of photorealism.',
            models: [
                { id: 'imagen', name: 'Imagen', api: 'imagen-3.0-generate-002' },
                { id: 'imagen-4', name: 'Imagen 4', api: 'imagen-3.0-generate-002' },
                { id: 'imagen-generation', name: 'Imagen for Generation', api: 'imagen-3.0-generate-002' },
                { id: 'imagen-fast', name: 'Imagen for Fast Generation', api: 'imagen-3.0-generate-002' },
                { id: 'imagen-editing', name: 'Imagen for Editing and Customization', api: 'mock' },
                { id: 'imagen-captioning', name: 'Imagen for Captioning & VQA', api: 'mock' }
            ]
        },
        "Legacy": {
            type: 'text',
            title: 'Historical/Legacy Models',
            description: 'Foundational models that paved the way for modern AI, primarily focused on natural language processing.',
            models: [
                { id: 'palm', name: 'PaLM', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'lamda', name: 'LaMDA', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'bert', name: 'BERT', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 't5', name: 'T5', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'chirp', name: 'Chirp (Speech-to-Text)', api: 'mock' },
                { id: 'text-bison', name: 'text-bison (PaLM variant)', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'chat-bison', name: 'chat-bison (PaLM variant)', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'code-gecko', name: 'code-gecko (PaLM variant)', api: 'gemini-2.5-flash-preview-05-20' },
                { id: 'textembedding-gecko', name: 'textembedding-gecko', api: 'mock' }
            ]
        }
    };

    // --- DOM Elements ---
    const navigation = document.getElementById('model-navigation');
    const welcomeScreen = document.getElementById('welcome-screen');
    const modelInterfacesContainer = document.getElementById('model-interfaces');
    
    // Interface elements
    const textInterface = document.getElementById('text-generation-interface');
    const textTitle = document.getElementById('text-model-title');
    const textDescription = document.getElementById('text-model-description');
    const textModelSelector = document.getElementById('text-model-selector');
    const chatContainer = document.getElementById('chat-container');
    const textPromptInput = document.getElementById('text-prompt-input');
    const sendTextBtn = document.getElementById('send-text-prompt-btn');

    const imageInterface = document.getElementById('image-generation-interface');
    const imageTitle = document.getElementById('image-model-title');
    const imageDescription = document.getElementById('image-model-description');
    const imageModelSelector = document.getElementById('image-model-selector');
    const imagePromptInput = document.getElementById('image-prompt-input');
    const sendImageBtn = document.getElementById('send-image-prompt-btn');
    const imageDisplayArea = document.getElementById('image-display-area');

    // --- Initialization ---
    function initialize() {
        renderSidebar();
        attachEventListeners();
    }

    // --- UI Rendering ---
    function renderSidebar() {
        const categories = Object.keys(modelData);
        let navHtml = '<ul class="space-y-2">';
        categories.forEach(categoryKey => {
            navHtml += `<li><a href="#" data-category="${categoryKey}" class="flex items-center p-2 text-gray-600 rounded-lg hover:bg-gray-100 transition-colors">${modelData[categoryKey].title}</a></li>`;
        });
        navHtml += '</ul>';
        navigation.innerHTML = navHtml;
    }

    function showInterface(categoryKey) {
        welcomeScreen.classList.add('hidden');
        modelInterfacesContainer.classList.remove('hidden');

        // Hide all interfaces
        [textInterface, imageInterface].forEach(el => el.classList.add('hidden'));

        const category = modelData[categoryKey];
        switch(category.type) {
            case 'text':
                setupTextInterface(category);
                break;
            case 'image':
                setupImageInterface(category);
                break;
        }
    }
    
    function setupTextInterface(category) {
        textTitle.textContent = category.title;
        textDescription.textContent = category.description;
        textModelSelector.innerHTML = category.models.map(m => `<option value="${m.api}">${m.name}</option>`).join('');
        chatContainer.innerHTML = '';
        textPromptInput.value = '';
        textInterface.classList.remove('hidden');
    }

    function setupImageInterface(category) {
        imageTitle.textContent = category.title;
        imageDescription.textContent = category.description;
        imageModelSelector.innerHTML = category.models.map(m => `<option value="${m.api}">${m.name}</option>`).join('');
        imagePromptInput.value = '';
        imageDisplayArea.innerHTML = '<div id="image-placeholder" class="text-gray-500">Your generated image will appear here.</div>';
        imageInterface.classList.remove('hidden');
    }
    
    function addChatMessage(sender, message, isHtml = false) {
        const bubble = document.createElement('div');
        const outerDiv = document.createElement('div');
        outerDiv.classList.add('w-full', 'flex', 'mb-2');

        bubble.classList.add('chat-bubble', 'p-3', 'rounded-lg', 'flex', 'items-start', 'space-x-3');
        
        let content = '';
        if (sender === 'user') {
            bubble.classList.add('bg-blue-600', 'text-white');
            outerDiv.classList.add('justify-end');
            content = `<p>${message}</p>`;
        } else {
            bubble.classList.add('bg-gray-200', 'text-gray-800');
            outerDiv.classList.add('justify-start');
            const icon = `<div class="w-6 h-6 flex-shrink-0 bg-gray-300 rounded-full flex items-center justify-center">
                            <svg class="w-4 h-4 text-blue-500" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path></svg>
                         </div>`;
            if (isHtml) {
                content = `${icon}<div>${message}</div>`;
            } else {
                content = `${icon}<p>${message}</p>`;
            }
        }
        
        bubble.innerHTML = content;
        outerDiv.appendChild(bubble);
        chatContainer.appendChild(outerDiv);
        chatContainer.scrollTop = chatContainer.scrollHeight;
    }

    // --- Event Handlers ---
    function attachEventListeners() {
        navigation.addEventListener('click', (e) => {
            e.preventDefault();
            const link = e.target.closest('a');
            if (link) {
                const categoryKey = link.dataset.category;
                if (categoryKey) {
                    document.querySelectorAll('#model-navigation a').forEach(a => {
                        a.classList.remove('bg-blue-50', 'text-blue-600', 'font-semibold');
                    });
                    link.classList.add('bg-blue-50', 'text-blue-600', 'font-semibold');
                    showInterface(categoryKey);
                }
            }
        });

        sendTextBtn.addEventListener('click', handleTextPrompt);
        textPromptInput.addEventListener('keyup', (e) => {
            if (e.key === 'Enter') handleTextPrompt();
        });

        sendImageBtn.addEventListener('click', handleImagePrompt);
        imagePromptInput.addEventListener('keyup', (e) => {
            if (e.key === 'Enter') handleImagePrompt();
        });
    }

    async function handleTextPrompt() {
        const prompt = textPromptInput.value.trim();
        if (!prompt) return;

        addChatMessage('user', prompt);
        textPromptInput.value = '';
        setLoadingState(sendTextBtn, true);

        const modelApi = textModelSelector.value;
        const selectedModelName = textModelSelector.options[textModelSelector.selectedIndex].text;

        try {
            let responseText;
            if (modelApi.startsWith('gemini')) {
                responseText = await callGeminiApi(prompt);
            } else {
                responseText = simulateApiResponse(selectedModelName, prompt);
            }
            addChatMessage('ai', responseText, true);
        } catch (error) {
            console.error('Error:', error);
            addChatMessage('ai', `Sorry, an error occurred: ${error.message}`);
        } finally {
            setLoadingState(sendTextBtn, false);
        }
    }

    async function handleImagePrompt() {
        const prompt = imagePromptInput.value.trim();
        if (!prompt) return;

        imagePromptInput.value = '';
        setLoadingState(sendImageBtn, true, true);
        imageDisplayArea.innerHTML = `<div class="flex flex-col items-center justify-center text-gray-500">
            <svg class="animate-spin h-8 w-8 text-gray-600 mb-2" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg>
            Generating image for: "${prompt}"
        </div>`;

        const modelApi = imageModelSelector.value;
        const selectedModelName = imageModelSelector.options[imageModelSelector.selectedIndex].text;
        
        try {
            if (modelApi.startsWith('imagen')) {
                const imageUrl = await callImagenApi(prompt);
                imageDisplayArea.innerHTML = `<img src="${imageUrl}" alt="${prompt}" class="max-h-full max-w-full object-contain rounded-lg">`;
            } else {
                 imageDisplayArea.innerHTML = `<div class="text-center p-4 bg-gray-100 rounded-lg">
                    <h4 class="font-bold mb-2">Simulation Mode</h4>
                    <p class="text-sm text-gray-600">The '${selectedModelName}' model would now process your request. As this is a conceptual demo for this specific model, a placeholder is shown instead of a live generation.</p>
                    <img src="https://placehold.co/512x512/e5e7eb/4b5563?text=Conceptual+Output" class="mt-4 rounded-md mx-auto" alt="Conceptual output placeholder">
                 </div>`;
            }
        } catch(error) {
            console.error('Error generating image:', error);
            imageDisplayArea.innerHTML = `<div class="text-red-500">Error: ${error.message}</div>`;
        } finally {
            setLoadingState(sendImageBtn, false, true);
        }
    }
    
    function setLoadingState(button, isLoading, isImage = false) {
        button.disabled = isLoading;
        const originalContent = isImage 
            ? '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12v7a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h7"/><line x1="16" x2="22" y1="5" y2="5"/><line x1="19" x2="19" y1="2" y2="8"/><circle cx="9" cy="9" r="2"/><path d="m21 15-3.086-3.086a2 2 0 0 0-2.828 0L6 21"/></svg>'
            : '<svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>';
            
        if (isLoading) {
            button.innerHTML = '<svg class="animate-spin h-6 w-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg>';
        } else {
            button.innerHTML = originalContent;
        }
    }

    // --- API & Simulation Logic ---
    function simulateApiResponse(modelName, prompt) {
        let response = `Simulating response from <strong>${modelName}</strong>.<br><br>`;
        switch (modelName) {
            case 'PaliGemma':
                response += 'This is a vision-language model. It would analyze an image related to your prompt and provide a text-based answer, such as captions or answering questions about the image content.';
                break;
            case 'MedGemma':
                response += 'As a medical-focused model, I would provide information from medical literature or analyze medical data related to your prompt, with the appropriate disclaimers.';
                break;
            case 'ShieldGemma':
                 response += 'This model is designed for safety and trust applications. I would analyze your prompt for any potential policy violations or harmful content and provide a filtered, safe response.';
                 break;
            case 'EmbeddingGemma':
            case 'textembedding-gecko':
                 response += 'Instead of a chat response, I would convert your prompt into a dense vector (a series of numbers) called an embedding. This is useful for semantic search, clustering, and other machine learning tasks.';
                break;
            case 'Chirp (Speech-to-Text)':
                response += 'If this were a voice input, I would transcribe your speech to text. Since you typed, the transcription would be: "' + prompt + '"';
                break;
            default:
                response += 'This is a conceptual demonstration. A real response from this model would be generated based on its specific training and capabilities, tailored to your prompt: "' + prompt + '"';
                break;
        }
        return response;
    }
    
    async function callGeminiApi(userQuery) {
        const apiKey = ""; // Canvas will provide this
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${apiKey}`;
        const payload = {
            contents: [{ parts: [{ text: userQuery }] }]
        };

        const response = await fetch(apiUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(payload)
        });

        if (!response.ok) {
            const errorBody = await response.json();
            throw new Error(`API Error: ${errorBody.error.message}`);
        }

        const result = await response.json();
        const text = result.candidates?.[0]?.content?.parts?.[0]?.text;
        if (text) {
            // Basic markdown-to-HTML conversion
            return text
                .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')
                .replace(/\*(.*?)\*/g, '<em>$1</em>')
                .replace(/\n/g, '<br>');
        } else {
            return "No content received from the API.";
        }
    }
    
    async function callImagenApi(prompt) {
        const apiKey = ""; // Canvas will provide this
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-generate-002:predict?key=${apiKey}`;
        const payload = {
            instances: [{ prompt: prompt }],
            parameters: { "sampleCount": 1 }
        };

        const response = await fetch(apiUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(payload)
        });

        if (!response.ok) {
            const errorBody = await response.json();
            throw new Error(`API Error: ${errorBody.error.message || 'Failed to generate image'}`);
        }

        const result = await response.json();
        if (result.predictions && result.predictions[0]?.bytesBase64Encoded) {
            return `data:image/png;base64,${result.predictions[0].bytesBase64Encoded}`;
        } else {
            throw new Error('Invalid response from image generation API.');
        }
    }

    // --- Start the App ---
    initialize();

</script>
</body>
</html>

